from playwright.sync_api import sync_playwright
import dateparser
from collections import defaultdict
import requests
import sqlite3
from pathlib import Path
from datetime import datetime

# NOTE: These functions must be defined in intervals_cleaning.py
from intervals_cleaning import normalise_row, merge_rows, export_rows 

# ---------------------------------------------------------
#  Incremental helpers
# ---------------------------------------------------------

def load_existing(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f if line.strip())
    except FileNotFoundError:
        return set()


def save_existing(path, rows):
    with open(path, "w", encoding="utf-8") as f:
        for r in sorted(rows):
            f.write(r + "\n")


CINEMA_NAME = "Prince Charles Cinema"

# ---------------------------------------------------------
#  YOUR TMDB API KEY
# ---------------------------------------------------------
# REMINDER: Replace this with your actual, valid TMDB API key
TMDB_API_KEY = "63ca1bc21617054972b7bc2c64db096b"

# ---------------------------------------------------------
#  SQLite TMDB cache
# ---------------------------------------------------------
DB_PATH = Path(__file__).with_name("tmdb_cache.db")
_MEM_CACHE = {}


def init_db():
    conn = sqlite3.connect(DB_PATH)
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS tmdb_cache (
            title TEXT NOT NULL,
            year_hint TEXT,
            tmdb_id INTEGER,
            runtime_min INTEGER,
            director TEXT,
            final_year TEXT,
            last_updated TEXT,
            PRIMARY KEY (title, year_hint)
        )
        """
    )
    conn.commit()
    return conn


def tmdb_get_metadata(conn, title: str, year_hint: str | None):
    key = (title, year_hint or "")

    # 1. In-memory
    if key in _MEM_CACHE:
        return _MEM_CACHE[key]

    # 2. SQLite cache
    cur = conn.execute(
        "SELECT runtime_min, director, final_year FROM tmdb_cache WHERE title = ? AND year_hint IS ?",
        (title, year_hint),
    )
    row = cur.fetchone()
    if row:
        runtime_min, director, final_year = row
        meta = {
            "runtime_min": runtime_min,
            "director": director,
            "year": final_year or year_hint,
        }
        _MEM_CACHE[key] = meta
        return meta

    # 3. TMDB API fetch
    if not TMDB_API_KEY:
        meta = {"runtime_min": None, "director": None, "year": year_hint}
        _MEM_CACHE[key] = meta
        return meta

    try:
        # Search
        params = {"api_key": TMDB_API_KEY, "query": title}
        if year_hint:
            params["year"] = year_hint

        r = requests.get(
            "https://api.themoviedb.org/3/search/movie", params=params, timeout=10
        )
        r.raise_for_status()

        results = r.json().get("results") or []
        if not results:
            meta = {"runtime_min": None, "director": None, "year": year_hint}
            _MEM_CACHE[key] = meta
            return meta

        movie = results[0]
        if year_hint:
            for m in results:
                rd = (m.get("release_date") or "")[:4]
                if rd == str(year_hint):
                    movie = m
                    break

        movie_id = movie.get("id")
        if not movie_id:
            meta = {"runtime_min": None, "director": None, "year": year_hint}
            _MEM_CACHE[key] = meta
            return meta

        # Details + credits
        r2 = requests.get(
            f"https://api.themoviedb.org/3/movie/{movie_id}",
            params={"api_key": TMDB_API_KEY, "append_to_response": "credits"},
            timeout=10,
        )
        r2.raise_for_status()
        mdata = r2.json()

        runtime_min = mdata.get("runtime")
        release_date = mdata.get("release_date") or ""
        tmdb_year = release_date[:4] if release_date else None

        director = None
        for c in mdata.get("credits", {}).get("crew", []):
            if c.get("job") == "Director":
                director = c.get("name")
                break

        final_year = tmdb_year or year_hint

        meta = {
            "runtime_min": runtime_min,
            "director": director,
            "year": final_year,
        }

        # Save to DB
        conn.execute(
            """
            INSERT OR REPLACE INTO tmdb_cache
                (title, year_hint, tmdb_id, runtime_min, director, final_year, last_updated)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
            (
                title,
                year_hint,
                movie_id,
                runtime_min,
                director,
                final_year,
                datetime.utcnow().isoformat(),
            ),
        )
        conn.commit()

        _MEM_CACHE[key] = meta
        return meta

    except Exception:
        meta = {"runtime_min": None, "director": None, "year": year_hint}
        _MEM_CACHE[key] = meta
        return meta


def scrape_pcc():
    url = "https://princecharlescinema.com/whats-on/"
    conn = init_db()
    showtimes = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        print("Loading PCC What's On…")
        page.goto(url, timeout=60000)
        page.wait_for_selector("div.film_list-outer")

        films = page.locator("div.film_list-outer")
        total = films.count()
        print(f"Found {total} films\n")

        for i in range(total):
            f = films.nth(i)
            print(f"[{i+1}/{total}] Extracting film…")

            title = f.locator("a.liveeventtitle").inner_text().strip()
            link = f.locator("a.liveeventtitle").get_attribute("href")

            # year hint
            spans = f.locator("div.running-time span").all_inner_texts()
            pcc_year = None
            for s in spans:
                s = s.strip()
                if s.isdigit() and len(s) == 4:
                    pcc_year = s

            # projection format ONLY
            tags = f.locator("span.tag").all_inner_texts()
            projection_format = ""
            for t in tags:
                t = t.strip().upper()
                if any(fmt in t for fmt in ["70MM", "35MM", "16MM", "DCP", "DIGITAL"]):
                    projection_format = t
                    break

            # times
            perf = f.locator("ul.performance-list-items")
            children = perf.locator(":scope > *")

            grouped = defaultdict(list)
            current_date = None

            for j in range(children.count()):
                el = children.nth(j)
                tag = el.evaluate("e => e.tagName.toLowerCase()")

                if tag == "div":
                    if "heading" in (el.get_attribute("class") or ""):
                        current_date = el.inner_text().strip()
                elif tag == "li" and current_date:
                    t_el = el.locator("span.time")
                    if t_el.count():
                        t = t_el.inner_text().strip()
                        if t:
                            grouped[current_date].append(t)

            if not grouped:
                continue

            # TMDB metadata
            meta = tmdb_get_metadata(conn, title, pcc_year)
            runtime_min = meta.get("runtime_min")
            director = meta.get("director") or ""
            final_year = meta.get("year") or pcc_year or ""

            # build rows
            for date_str, times in grouped.items():

                # pick EARLIEST time (for row)
                times_sorted = sorted(times)

                # parse date
                dt = dateparser.parse(f"{date_str} {times_sorted[0]}")
                if not dt:
                    continue

                # ---- YEAR ROLLOVER FIX ----
                today = datetime.today()
                if dt.month in (1, 2) and today.month in (11, 12):
                    dt = dt.replace(year=today.year + 1)

                date_out = dt.strftime("%Y-%m-%d")

                raw = {
                    "venue": CINEMA_NAME,
                    "date": date_out,
                    "title": title,
                    "times": times_sorted,
                    "format": projection_format,
                    "extra": "",
                    "url": link,
                }

                normal = normalise_row(raw)
                merge_rows(showtimes, normal)

    # NO LONGER A SYNTAX ERROR HERE ^

        browser.close()
        conn.close()

    # sort by date (Sorting logic is omitted but assumed to happen via merge/export functions)
    return showtimes


if __name__ == "__main__":
    listings = scrape_pcc()

    # Export rows into semicolon-delimited lines
    all_rows = export_rows(listings).split("\n")

    # Load what’s already in your CMS (via local memory file)
    existing = load_existing("pcc_existing.txt")

    # Keep only NEW rows
    new_rows = [r for r in all_rows if r not in existing]

    # Update local memory file
    updated = existing.union(new_rows)
    save_existing("pcc_existing.txt", updated)

    # Output only NEW rows for CMS paste
    print("\n".join(new_rows))
