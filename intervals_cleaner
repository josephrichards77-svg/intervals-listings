"""
intervals_cleaning.py

Shared cleaning, normalisation, merging, exporting for all scrapers.
"""

import re
import html


# ============================================================
# CLEANER — OPTION B (strip only matched quotes)
# ============================================================

def clean(text):
    """Clean text while preserving unmatched leading apostrophes (e.g. ’71)."""
    if text is None:
        return ""

    s = str(text)
    s = html.unescape(s).strip()

    # Strip only matched pairs
    matched = [
        ('"', '"'),
        ("'", "'"),
        ("“", "”"),
        ("‘", "’"),
    ]

    for left, right in matched:
        if s.startswith(left) and s.endswith(right):
            return s[len(left):-len(right)].strip()

    # Collapse multiple spaces
    s = re.sub(r"\s{2,}", " ", s).strip()
    return s


# ============================================================
# ROW NORMALISER — unified schema
# ============================================================

def normalise_row(row):

    normal = {
        "venue": "",
        "date": "",
        "title": "",
        "times": [],
        "format": "",
        "extra": "",
        "url": "",
        "director": "",
        "runtime_min": "",
        "year": "",
    }

    for key in normal:
        if key not in row:
            continue

        if key == "times":
            if isinstance(row[key], list):
                normal[key] = [clean(t) for t in row[key] if t]
            else:
                t = clean(row[key])
                normal[key] = [t] if t else []
        else:
            normal[key] = clean(row[key]) if isinstance(row[key], str) else row[key]

    return normal


# ============================================================
# MERGE — one row per (venue, date, title)
# ============================================================

def merge_rows(existing, new):

    key = (new["venue"], new["date"], new["title"])

    for row in existing:
        if (row["venue"], row["date"], row["title"]) == key:

            # Merge times (dedupe)
            for t in new["times"]:
                if t not in row["times"]:
                    row["times"].append(t)

            # Fill metadata if missing
            for field in ["format", "extra", "url", "director", "runtime_min", "year"]:
                if not row[field] and new[field]:
                    row[field] = new[field]

            return

    existing.append(new)


# ============================================================
# EXPORT — your required format
# DATE;VENUE;TITLE;DIRECTOR;RUNTIME;FORMAT;TIME;YEAR;NOTES
# ============================================================

def export_rows(rows):

    rows_sorted = sorted(rows, key=lambda r: (r["date"], r["title"]))

    lines = []
    for r in rows_sorted:

        times_str = ", ".join(sorted(r["times"]))

        line = ";".join([
            r["date"],
            r["venue"],
            r["title"],
            r["director"],
            str(r["runtime_min"] or ""),
            r["format"],
            times_str,
            r["year"],
            r["extra"],
        ])

        lines.append(line)

    return "\n".join(lines)
