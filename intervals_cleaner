"""
intervals_cleaning.py

Shared cleaning, normalisation, merging, exporting for all scrapers.
"""

import re
import html
from datetime import datetime

# ============================================================
# DEBUG SWITCH
# ============================================================
DEBUG_CLEANING = False


# ============================================================
# BASIC CLEANER
# ============================================================

def clean(text):
    """General cleaner: quote trimming, HTML unescape, collapse spaces."""

    if DEBUG_CLEANING:
        print("CLEANING INPUT:", repr(text))

    if text is None:
        s = ""
    else:
        s = str(text)

    # HTML entities
    s = html.unescape(s).strip()

    # Strip paired quotes
    quote_pairs = [
        ('"', '"'),
        ("'", "'"),
        ("“", "”"),
        ("‘", "’"),
    ]
    for left, right in quote_pairs:
        if s.startswith(left) and s.endswith(right):
            s = s[len(left):-len(right)].strip()
            break

    # Fix ALL-CAPS (only if not HTML)
    if "<" not in s and s.isupper() and len(s) > 3:
        s = s.title()

    # Collapse multiple spaces
    s = re.sub(r"\s{2,}", " ", s)

    if DEBUG_CLEANING:
        print("CLEANED OUTPUT:", repr(s))

    return s


# ============================================================
# FORMAT NORMALISER
# ============================================================

def normalise_format(fmt):
    """Force formats into consistent set."""

    if not fmt or fmt.strip() == "":
        return "DCP"

    f = fmt.strip().upper().replace(" ", "").replace("-", "")

    # 4K variants → DCP
    if f in ["4K", "4KRESTORATION", "4"]:
        return "DCP"

    # digital equivalents → DCP
    if f in ["DIGITAL", "HD", "DCP"]:
        return "DCP"

    # physical formats
    if f in ["35MM", "35"]:
        return "35mm"
    if f in ["70MM", "70"]:
        return "70mm"
    if f in ["16MM", "16"]:
        return "16mm"

    return fmt.strip()


# ============================================================
# TIME NORMALISER (ALWAYS 24H)
# ============================================================

def normalise_time(t):
    """Convert all AM/PM times to HH:MM 24-hour format."""

    if not t:
        return ""

    s = t.replace(".", "").strip().upper()

    # Already 24h
    if re.fullmatch(r"\d{2}:\d{2}", s):
        return s

    # Match "8:30 PM"
    m = re.match(r"^(\d{1,2}):(\d{2})\s*(AM|PM)$", s)
    if not m:
        return s  # leave unchanged

    hh, mm, suffix = m.groups()
    hh = int(hh)

    if suffix == "PM" and hh != 12:
        hh += 12
    if suffix == "AM" and hh == 12:
        hh = 0

    return f"{hh:02d}:{mm}"


# ============================================================
# NORMALISER — unify keys + clean everything
# ============================================================

def normalise_row(row):
    """Ensure consistent keys + clean strings everywhere."""

    normal = {
        "venue": "",
        "date": "",
        "title": "",
        "director": "",
        "runtime_min": "",
        "format": "",
        "times": [],
        "year": "",
        "extra": "",
        "url": "",
    }

    for key in normal:
        if key not in row:
            continue

        val = row[key]

        # Times → list of cleaned + normalised 24h times
        if key == "times":
            out = []
            if isinstance(val, list):
                for t in val:
                    if t:
                        out.append(normalise_time(clean(t)))
            elif val:
                out = [normalise_time(clean(str(val)))]
            normal[key] = out
            continue

        # FORMAT normalisation
        if key == "format":
            normal[key] = normalise_format(val)
            continue

        # Everything else → cleaned string
        normal[key] = clean(val) if val else ""

    return normal


# ============================================================
# MERGING — one row per (venue, date, title)
# ============================================================

def merge_rows(existing, new):
    key = (new["venue"], new["date"], new["title"])

    for row in existing:
        if (row["venue"], row["date"], row["title"]) == key:

            # merge times
            for t in new["times"]:
                if t not in row["times"]:
                    row["times"].append(t)

            # fill missing metadata
            for field in [
                "format", "extra", "url",
                "director", "runtime_min", "year"
            ]:
                if not row[field] and new[field]:
                    row[field] = new[field]

            return

    existing.append(new)


# ============================================================
# EXPORT — fixed 9-column semicolon format
# ============================================================

def export_rows(rows):
    rows_sorted = sorted(rows, key=lambda r: (r["date"], r["title"]))

    def field(x):
        return x if x else " "

    lines = []

    for r in rows_sorted:

        times = ", ".join(sorted(r.get("times", []))) if r.get("times") else ""

        line = ";".join([
            field(r.get("date", "")),
            field(r.get("venue", "")),
            field(r.get("title", "")),
            field(r.get("director", "")),
            field(str(r.get("runtime_min") or "")),
            field(r.get("format", "")),
            field(times),
            field(r.get("year", "")),
            field(r.get("extra", "")),
        ])

        lines.append(line)

    return "\n".join(lines)
