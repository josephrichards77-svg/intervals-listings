import re
import json
import sqlite3
import requests
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass

from playwright.sync_api import sync_playwright
from rich import print

# ======================================================
# CONFIG
# ======================================================

CINEMA_SHORTCODE = "CL"
CINEMA_NAME = "Institut français"
BASE_URL = "https://www.institut-francais.org.uk"
URL = f"{BASE_URL}/whats-on/?type=72&period=any&location=onsite#/"
OUTPUT_FILE = "institut_francais.txt"
DATA_FILE = "if_existing.json"

TMDB_API_KEY = "63ca1bc21617054972b7bc2c64db096b"
TMDB_DB = "tmdb_cache.db"

RELEASE_YEAR_RE = re.compile(r"\b(19\d{2}|20[0-2]\d)\b")


# ======================================================
# FALLBACK DATACLASS (replaces cinescrapers ShowTime)
# ======================================================

@dataclass
class ShowTime:
    cinema_shortcode: str
    title: str
    link: str
    datetime: datetime
    description: str
    image_src: str
    release_year: int | str | None
    extra: dict


# ======================================================
# TITLE CLEANER
# ======================================================

def clean_title(title: str) -> str:
    """Fix ALL CAPS, remove double spaces, trim."""
    if title.isupper():
        title = title.title()
    title = re.sub(r"\s+", " ", title).strip()
    return title


# ======================================================
# TMDB FALLBACK (only if website misses data)
# ======================================================

def tmdb_get(title: str, year_hint: int | None):
    """Return dict: {runtime_min, director, year}"""
    if not TMDB_API_KEY:
        return {}

    conn = sqlite3.connect(TMDB_DB)
    cur = conn.cursor()

    # Try cache
    cur.execute("""
        SELECT runtime_min, director, final_year
        FROM tmdb_cache
        WHERE title = ? AND year_hint = ?
    """, (title, str(year_hint) if year_hint else None))

    row = cur.fetchone()
    if row:
        runtime, director, year = row
        conn.close()
        return {
            "runtime_min": runtime,
            "director": director,
            "year": year
        }

    # Query TMDB
    params = {"api_key": TMDB_API_KEY, "query": title}
    if year_hint:
        params["year"] = year_hint

    r = requests.get("https://api.themoviedb.org/3/search/movie", params=params).json()
    results = r.get("results") or []
    if not results:
        conn.close()
        return {}

    movie = results[0]
    tmdb_id = movie["id"]
    final_year = (movie.get("release_date") or "")[:4]

    # Details + credits
    d = requests.get(
        f"https://api.themoviedb.org/3/movie/{tmdb_id}",
        params={"api_key": TMDB_API_KEY, "append_to_response": "credits"},
    ).json()

    runtime = d.get("runtime")
    director = ""
    for c in d.get("credits", {}).get("crew", []):
        if c.get("job") == "Director":
            director = c["name"]
            break

    # Store cache
    cur.execute("""
        INSERT OR REPLACE INTO tmdb_cache
        (title, year_hint, tmdb_id, runtime_min, director, final_year, last_updated)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    """, (
        title,
        str(year_hint) if year_hint else None,
        tmdb_id,
        runtime,
        director,
        final_year,
        datetime.utcnow().isoformat(),
    ))
    conn.commit()
    conn.close()

    return {
        "runtime_min": runtime,
        "director": director,
        "year": final_year,
    }


# ======================================================
# SCRAPER (your working logic, unbroken)
# ======================================================

def scrape():
    showtimes = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(URL)

        articles = page.locator("article")
        total = articles.count()
        print(f"Found {total} films")

        for i in range(total):
            print(f"Film {i+1}/{total}")
            article = articles.nth(i)

            article_a = article.locator(":scope >a")
            link = article_a.get_attribute("href")
            if not link or "/festivals-and-series/" in link:
                continue

            film_page = browser.new_page()
            film_page.goto(link)

            # TITLE
            title = film_page.locator("meta[property='og:title']").get_attribute("content")
            title = clean_title(
                title.replace(
                    " at Ciné Lumière - Institut Français · Royaume-Uni", ""
                ).strip()
            )

            description = film_page.locator(
                "meta[property='og:description']"
            ).get_attribute("content")

            image_src = film_page.locator(
                "meta[property='og:image']"
            ).get_attribute("content")

            # YEAR FROM SITE
            metadata_items = film_page.locator("ul.metadata li")
            release_year = None

            for j in range(metadata_items.count()):
                t = metadata_items.nth(j).text_content().strip()
                m = RELEASE_YEAR_RE.search(t)
                if m:
                    release_year = int(m.group(1))
                    break

            # TMDB fallback
            meta = tmdb_get(title, release_year)
            runtime_min = meta.get("runtime_min") or ""
            director = meta.get("director") or ""
            final_year = release_year or meta.get("year") or ""

            # SHOWTIMES TABLE
            table = film_page.locator("table")

            if table.count() == 0:
                # No table → single screening layout
                timetable = film_page.locator("div.timetable")
                date_str = timetable.locator("div.date time").get_attribute("datetime")
                time_str = timetable.locator("time.time").get_attribute("datetime")
                dt = datetime.fromisoformat(f"{date_str} {time_str}")

                showtimes.append(ShowTime(
                    cinema_shortcode=CINEMA_SHORTCODE,
                    title=title,
                    link=link,
                    datetime=dt,
                    description=description,
                    image_src=image_src,
                    release_year=final_year,
                    extra={"director": director, "runtime_min": runtime_min},
                ))
            else:
                # Multiple screenings table
                rows = table.locator("tr")
                for r in range(rows.count()):
                    row = rows.nth(r)
                    if row.locator("th").count() > 0:
                        continue

                    date_str = row.locator("time.date").get_attribute("datetime")
                    time_str = row.locator("time.time").get_attribute("datetime")
                    dt = datetime.fromisoformat(f"{date_str} {time_str}")

                    showtimes.append(ShowTime(
                        cinema_shortcode=CINEMA_SHORTCODE,
                        title=title,
                        link=link,
                        datetime=dt,
                        description=description,
                        image_src=image_src,
                        release_year=final_year,
                        extra={"director": director, "runtime_min": runtime_min},
                    ))

            film_page.close()

        browser.close()
        page.close()

    return showtimes


# ======================================================
# INCREMENTAL STORAGE
# ======================================================

def load_existing():
    if not Path(DATA_FILE).exists():
        return []
    return json.loads(Path(DATA_FILE).read_text())


def save_existing(data):
    Path(DATA_FILE).write_text(json.dumps(data, indent=2))


def merge(old, new):
    merged = {(s["title"], s["datetime"]): s for s in old}

    for s in new:
        key = (s.title, s.datetime.isoformat())
        merged[key] = {
            "title": s.title,
            "datetime": s.datetime.isoformat(),
            "link": s.link,
            "year": s.release_year,
            "director": s.extra.get("director"),
            "runtime": s.extra.get("runtime_min"),
        }

    return list(merged.values())


# ======================================================
# EXPORT
# ======================================================

def export(rows):
    out = []

    for r in rows:
        dt = datetime.fromisoformat(r["datetime"])
        date_s = dt.date().isoformat()
        time_s = dt.strftime("%H:%M")

        title_html = f'<a href="{r["link"]}">{r["title"]}</a>'

        out.append(
            f"{date_s};{CINEMA_NAME};{title_html};"
            f"{r['director'] or ''};{r['runtime'] or ''};Digital;"
            f"{time_s};{r['year'] or ''};"
        )

    out.sort()
    Path(OUTPUT_FILE).write_text("\n".join(out), encoding="utf-8")
    print(f"Saved → {OUTPUT_FILE}")


# ======================================================
# MAIN
# ======================================================

if __name__ == "__main__":
    new = scrape()
    old = load_existing()
    merged = merge(old, new)
    save_existing(merged)
    export(merged)
