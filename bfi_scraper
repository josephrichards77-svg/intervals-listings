from playwright.sync_api import sync_playwright
import dateparser
from collections import defaultdict
import requests
import sqlite3
from pathlib import Path
from datetime import datetime
import re

CINEMA_NAME = "BFI Southbank"

# ---------------------------------------------------------
#  TMDB API KEY – same as your PCC scraper
# ---------------------------------------------------------
TMDB_API_KEY = "63ca1bc21617054972b7bc2c64db096b"

# ---------------------------------------------------------
#  Shared SQLite cache – same file as PCC
# ---------------------------------------------------------
DB_PATH = Path(__file__).with_name("tmdb_cache.db")
_MEM_CACHE = {}  # in-memory cache for this run

# Same regex logic as cinescrapers for release year
RELEASE_YEAR_RE = re.compile(r"^[a-zA-Z -]+ (?P<year>(19\d\d)|2[012]\d\d)\..*$")


def init_db():
    conn = sqlite3.connect(DB_PATH)
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS tmdb_cache (
            title TEXT NOT NULL,
            year_hint TEXT,
            tmdb_id INTEGER,
            runtime_min INTEGER,
            director TEXT,
            final_year TEXT,
            last_updated TEXT,
            PRIMARY KEY (title, year_hint)
        )
        """
    )
    conn.commit()
    return conn


def tmdb_get_metadata(conn, title: str, year_hint: str | None):
    """
    Look up (title, year_hint) in:
      1) in-memory cache
      2) SQLite cache
      3) TMDB API (if needed)

    Returns dict:
      { "runtime_min": int|None, "director": str|None, "year": str|None }
    """
    key = (title, year_hint or "")

    # 1) in-memory cache
    if key in _MEM_CACHE:
        return _MEM_CACHE[key]

    # 2) SQLite cache
    cur = conn.execute(
        "SELECT runtime_min, director, final_year FROM tmdb_cache WHERE title = ? AND year_hint IS ?",
        (title, year_hint),
    )
    row = cur.fetchone()
    if row:
        runtime_min, director, final_year = row
        meta = {
            "runtime_min": runtime_min,
            "director": director,
            "year": final_year or year_hint,
        }
        _MEM_CACHE[key] = meta
        return meta

    # 3) TMDB API (if no key, just bail with hint)
    if not TMDB_API_KEY or TMDB_API_KEY == "YOUR_TMDB_API_KEY_HERE":
        meta = {"runtime_min": None, "director": None, "year": year_hint}
        _MEM_CACHE[key] = meta
        return meta

    try:
        # --- Search by title (and optional year_hint) ---
        params = {
            "api_key": TMDB_API_KEY,
            "query": title,
        }
        if year_hint:
            params["year"] = year_hint

        r = requests.get(
            "https://api.themoviedb.org/3/search/movie", params=params, timeout=10
        )
        r.raise_for_status()
        data = r.json()
        results = data.get("results") or []

        if not results:
            meta = {"runtime_min": None, "director": None, "year": year_hint}
            _MEM_CACHE[key] = meta
            return meta

        movie = results[0]
        if year_hint:
            for m in results:
                rd = (m.get("release_date") or "")[:4]
                if rd == str(year_hint):
                    movie = m
                    break

        movie_id = movie.get("id")
        if not movie_id:
            meta = {"runtime_min": None, "director": None, "year": year_hint}
            _MEM_CACHE[key] = meta
            return meta

        # --- Get details + credits ---
        params = {
            "api_key": TMDB_API_KEY,
            "append_to_response": "credits",
        }
        r2 = requests.get(
            f"https://api.themoviedb.org/3/movie/{movie_id}",
            params=params,
            timeout=10,
        )
        r2.raise_for_status()
        mdata = r2.json()

        runtime_min = mdata.get("runtime")

        release_date = mdata.get("release_date") or ""
        tmdb_year = release_date[:4] if release_date else None
        final_year = tmdb_year or year_hint

        director = None
        credits = (mdata.get("credits") or {}).get("crew") or []
        for c in credits:
            if c.get("job") == "Director":
                director = c.get("name")
                break

        meta = {
            "runtime_min": runtime_min,
            "director": director,
            "year": final_year,
        }

        # Store in SQLite
        conn.execute(
            """
            INSERT OR REPLACE INTO tmdb_cache
                (title, year_hint, tmdb_id, runtime_min, director, final_year, last_updated)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
            (
                title,
                year_hint,
                movie_id,
                runtime_min,
                director,
                final_year,
                datetime.utcnow().isoformat(),
            ),
        )
        conn.commit()

        _MEM_CACHE[key] = meta
        return meta

    except Exception:
        meta = {"runtime_min": None, "director": None, "year": year_hint}
        _MEM_CACHE[key] = meta
        return meta


def scrape_bfi():
    INDEX_URL = "https://whatson.bfi.org.uk/Online/article/filmsindex"
    showtimes = []

    conn = init_db()

    with sync_playwright() as p:
        # Headed browser like cinescrapers (Cloudflare is happier this way)
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()

        print("Loading BFI films index…")
        page.goto(INDEX_URL, timeout=60000)

        # Same strategy as cinescrapers: div.Rich-text contains the A–Z list
        listings_container = page.locator("div.Rich-text").first
        if listings_container.count() == 0:
            print("Could not find films container (div.Rich-text).")
            browser.close()
            conn.close()
            return showtimes

        lis = listings_container.locator("ul > li > a")
        total = lis.count()
        print(f"Found {total} films\n")

        for i in range(total):
            a = lis.nth(i)
            title = a.inner_text().strip()
            href = a.get_attribute("href")

            if not href:
                print(f"Skipping (no href): {title}")
                continue
            if not href.startswith("https://"):
                href = "https://whatson.bfi.org.uk/Online/" + href.lstrip("/")

            print(f"[{i+1}/{total}] Fetching: {title}")

            film_page = browser.new_page()
            try:
                film_page.goto(href, timeout=60000)

                # Grab the JS object articleContext that BFI embeds
                article_context = film_page.evaluate(
                    "(() => (typeof articleContext !== 'undefined' ? articleContext : null))()"
                )
                if not article_context:
                    print("  No articleContext, skipping")
                    film_page.close()
                    continue

                search_names = article_context.get("searchNames") or []
                search_results = article_context.get("searchResults") or []
                if not search_names or not search_results:
                    print("  No searchResults, skipping")
                    film_page.close()
                    continue

                listings = [dict(zip(search_names, row)) for row in search_results]

                # Release year hint from the film info block
                year_hint = None
                info_nodes = film_page.locator(
                    "p.Film-info__information__value"
                ).all_inner_texts()
                for info in info_nodes:
                    info = info.strip()
                    m = RELEASE_YEAR_RE.match(info)
                    if m:
                        year_hint = m.group("year")
                        break

                # TMDB metadata once per film
                meta = tmdb_get_metadata(conn, title, year_hint)
                runtime_min = meta.get("runtime_min")
                director = meta.get("director") or ""
                final_year = meta.get("year") or (year_hint or "")

                # You said: presume Digital/DCP and hand-edit
                default_format = "Digital"

                # Group times by date (one line per film per date)
                per_date = defaultdict(list)

                for listing in listings:
                    start_raw = listing.get("start_date") or listing.get("startDate")
                    if not start_raw:
                        continue

                    dt = dateparser.parse(start_raw)
                    if not dt:
                        continue

                    date_str = dt.strftime("%Y-%m-%d")
                    time_str = dt.strftime("%H:%M")
                    per_date[date_str].append(time_str)

                # Build final showtime rows, with times merged per date
                for date_str, times in per_date.items():
                    unique_times = sorted(set(times))
                    times_joined = ", ".join(unique_times)

                    showtimes.append(
                        {
                            "date": date_str,
                            "venue": CINEMA_NAME,
                            "title": title,
                            "director": director,
                            "runtime": f"{runtime_min} min" if runtime_min else "",
                            "format": default_format,
                            "time": times_joined,
                            "year": final_year,
                            "link": href,
                        }
                    )

            except Exception as e:
                print(f"  Error on {title}: {e}")
            finally:
                film_page.close()

        browser.close()
        conn.close()

    return showtimes


if __name__ == "__main__":
    listings = scrape_bfi()
    print(f"\nExtracted {len(listings)} BFI showtime rows.\n")
    print("------ FINAL BFI LISTINGS ------\n")
    for s in listings:
        print(
            f"{s['date']}; "
            f"{s['venue']}; "
            f"<a href=\"{s['link']}\" target=\"_blank\">{s['title']}</a>; "
            f"{s['director']}; "
            f"{s['runtime']}; "
            f"{s['format']}; "
            f"{s['time']}; "
            f"{s['year']}"
        )
