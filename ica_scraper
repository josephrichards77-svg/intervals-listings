import datetime
import re
import sqlite3
import time

import requests
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

TMDB_API_KEY = "63ca1bc21617054972b7bc2c64db096b"
BASE = "https://www.ica.art"


# ===========================
# TMDB CACHE HELPERS (unchanged)
# ===========================

def tmdb_lookup(title, year_hint):
    """Lookup film in local SQLite cache or fetch from TMDB."""
    conn = sqlite3.connect("tmdb_cache.db")
    c = conn.cursor()

    c.execute(
        "SELECT tmdb_id, runtime_min, director, final_year FROM tmdb_cache WHERE title=? AND year_hint=?",
        (title, str(year_hint) if year_hint else None)
    )
    row = c.fetchone()

    if row:
        tmdb_id, runtime, director, final_year = row
        conn.close()
        return runtime, director, final_year

    params = {"api_key": TMDB_API_KEY, "query": title}
    if year_hint:
        params["year"] = year_hint

    r = requests.get("https://api.themoviedb.org/3/search/movie", params=params)
    data = r.json()

    if not data.get("results"):
        conn.close()
        return None, None, None

    result = data["results"][0]
    movie_id = result["id"]
    final_year = result.get("release_date", "")[:4]

    d = requests.get(
        f"https://api.themoviedb.org/3/movie/{movie_id}",
        params={"api_key": TMDB_API_KEY, "append_to_response": "credits"},
    ).json()

    runtime = d.get("runtime")
    director = None
    for crew in d.get("credits", {}).get("crew", []):
        if crew.get("job") == "Director":
            director = crew.get("name")
            break

    ts = datetime.datetime.utcnow().isoformat(timespec="seconds")
    c.execute(
        "INSERT OR REPLACE INTO tmdb_cache (title, year_hint, tmdb_id, runtime_min, director, final_year, last_updated)"
        " VALUES (?, ?, ?, ?, ?, ?, ?)",
        (title, str(year_hint) if year_hint else None, movie_id, runtime, director, final_year, ts),
    )
    conn.commit()
    conn.close()

    return runtime, director, final_year


# ===========================
# UTILS
# ===========================

def clean_text(s):
    if not s:
        return ""
    return " ".join(s.replace("\n", " ").split())


# ===========================
# ICA FILM-PAGE METADATA SCRAPER
# ===========================

def extract_metadata_from_ica_page(url, page):
    """
    Extract director / runtime / year from ICA film page.
    This is used BEFORE TMDB. TMDB is fallback only.
    """
    try:
        page.goto(url, timeout=15000)
    except:
        return None, None, None, None

    soup = BeautifulSoup(page.content(), "html.parser")

    director = None
    runtime = None
    year = None
    country = None

    # Looks for the metadata block
    meta = soup.select_one(".field--name-field-film-details, .film-details-meta")
    if meta:
        text = meta.get_text(" ", strip=True)

        # Director
        m = re.search(r"Director[s]?:\s*(.+?)(?:\||$)", text)
        if m:
            director = m.group(1).strip()

        # Runtime
        m = re.search(r"(\d+)\s*min", text, re.I)
        if m:
            runtime = m.group(1).strip()

        # Year
        m = re.search(r"(19\d{2}|20[0-2]\d)", text)
        if m:
            year = m.group(1)

        # Country (optional)
        m = re.search(r"Country:\s*([A-Za-z ,]+)", text)
        if m:
            country = m.group(1).strip()

    return director, runtime, year, country


# ===========================
# SEASON + TITLE EXTRACTION
# ===========================

def extract_season(title_block):
    if title_block is None:
        return ""
    season_div = title_block.find("div", class_="title season-item")
    return clean_text(season_div.get_text()) if season_div else ""


def extract_title(title_block):
    if title_block is None:
        return ""
    parts = []
    for div in title_block.find_all("div", class_="title"):
        if "season-item" in div.get("class", []):
            continue
        parts.append(clean_text(div.get_text()))
    return " ".join([p for p in parts if p])


def extract_times(item):
    tdiv = item.find("div", class_="time-container")
    if not tdiv:
        return ""
    return ",".join(
        clean_text(t.get_text()) for t in tdiv.find_all("div", class_="time-slot")
    )


def extract_format():
    return "DCP"


# ===========================
# SCRAPE ONE DAY
# ===========================

def scrape_day(date_str, page, meta_page, results):
    url = f"{BASE}/{date_str}"
    print(f"Scraping {url}")

    try:
        page.goto(url, timeout=15000)
    except:
        print(" → page load failed")
        return False

    soup = BeautifulSoup(page.content(), "html.parser")
    items = soup.select(".item.films a")

    if not items:
        print(" → No films listed this day")
        return False

    for a in items:
        item_link = a.get("href")

        if not item_link or item_link.strip() == "/films":
            continue

        full_url = BASE + item_link

        title_block = a.find("div", class_="title-container")
        if title_block is None:
            continue

        season = extract_season(title_block)
        title = extract_title(title_block)
        if not title.strip():
            continue

        times = extract_times(a)

        # 1) Try ICA metadata first
        d_ica, r_ica, y_ica, _ = extract_metadata_from_ica_page(full_url, meta_page)

        # 2) TMDB fallback ONLY for blanks
        if not (d_ica and r_ica and y_ica):
            r_tmdb, d_tmdb, y_tmdb = tmdb_lookup(title, y_ica)
        else:
            r_tmdb = d_tmdb = y_tmdb = None

        director = d_ica or d_tmdb or ""
        runtime = r_ica or r_tmdb or ""
        year = y_ica or y_tmdb or ""

        fmt = extract_format()
        title_html = f'<a href="{full_url}">{title}</a>'

        line = (
            f"{date_str};"
            f"The ICA;"
            f"{title_html};"
            f"{director};"
            f"{runtime};"
            f"{fmt};"
            f"{times};"
            f"{year};"
            f"{season}"
        )

        results.append(line)

    return True


# ===========================
# MAIN
# ===========================

def run():
    results = []

    start_date = datetime.date.today()
    max_days = 120
    empty_days = 0

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        meta_page = browser.new_page()   # separate tab for ICA film-page metadata

        for i in range(max_days):
            day = start_date + datetime.timedelta(days=i)
            date_str = day.isoformat()

            found = scrape_day(date_str, page, meta_page, results)

            empty_days = empty_days + 1 if not found else 0
            if empty_days >= 2:
                print("Stopping: No screenings for 2 consecutive days.")
                break

            time.sleep(0.25)

        browser.close()

    with open("ica_output.txt", "w", encoding="utf-8") as f:
        for line in results:
            f.write(line + "\n")

    print("DONE → wrote", len(results), "rows to ica_output.txt")


if __name__ == "__main__":
    run()
